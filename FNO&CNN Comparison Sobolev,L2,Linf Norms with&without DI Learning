import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import torch.nn.functional as F
import pandas as pd

# Set device for computation
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load the full MNIST dataset with transformations
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])
full_dataset = datasets.MNIST(root='mnist_data', train=True, transform=transform, download=True)

# Split the dataset into training and validation sets
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

# Create DataLoader for training and validation datasets
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# Apply Gaussian blur
def apply_gaussian_blur(images, blur_transform):
    blurred_images = torch.stack([blur_transform(image) for image in images])
    return blurred_images.to(device)

gaussian_blur = transforms.GaussianBlur(kernel_size=5, sigma=1.0)

# Preprocess data
def preprocess_blurred_data(loader, blur_transform):
    blurred_images, original_images, labels = [], [], []
    for images, lbls in loader:
        images = images.to(device)
        blurred_images.append(apply_gaussian_blur(images, blur_transform))
        original_images.append(images)
        labels.append(lbls)
    blurred_images = torch.cat(blurred_images)
    original_images = torch.cat(original_images)
    labels = torch.cat(labels)
    return blurred_images, original_images, labels

train_blurred_images, train_original_images, train_labels = preprocess_blurred_data(train_loader, gaussian_blur)
val_blurred_images, val_original_images, val_labels = preprocess_blurred_data(val_loader, gaussian_blur)

# Dataset class
class BlurDataset(torch.utils.data.Dataset):
    def __init__(self, blurred_images, original_images, labels):
        assert len(blurred_images) == len(original_images) == len(labels)
        self.blurred_images = blurred_images
        self.original_images = original_images
        self.labels = labels

    def __len__(self):
        return len(self.blurred_images)

    def __getitem__(self, idx):
        return self.blurred_images[idx], self.original_images[idx], self.labels[idx]

train_dataset = BlurDataset(train_blurred_images, train_original_images, train_labels)
val_dataset = BlurDataset(val_blurred_images, val_original_images, val_labels)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# Extended Discretization Invariant Layer
class ExtendedDiscretizationInvariantLayer(nn.Module):
    def __init__(self, channels):
        super(ExtendedDiscretizationInvariantLayer, self).__init__()
        self.channels = channels
        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)
        self.local_avg_pool = nn.AvgPool2d(kernel_size=3, stride=1, padding=1)

        # Learnable scaling factors
        self.weight_global = nn.Parameter(torch.ones(channels))
        self.weight_local = nn.Parameter(torch.ones(channels))
        self.bias = nn.Parameter(torch.zeros(channels))

    def forward(self, x):
        x_global = self.global_avg_pool(x)
        x_local = self.local_avg_pool(x)
        x = x + self.weight_global.view(1, -1, 1, 1) * x_global + self.weight_local.view(1, -1, 1, 1) * x_local + self.bias.view(1, -1, 1, 1)
        return x

class SpectralConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, modes1, modes2):
        super(SpectralConv2d, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.modes1 = modes1
        self.modes2 = modes2

        self.scale = 1 / (in_channels * out_channels)
        self.weights1 = nn.Parameter(
            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))
        self.weights2 = nn.Parameter(
            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))

    def compl_mul2d(self, input, weights):
        return torch.einsum("bixy,ioxy->boxy", input, weights)

    def forward(self, x):
        batchsize = x.shape[0]
        x_ft = torch.fft.rfft2(x, dim=(-2, -1))

        out_ft = torch.zeros(
            batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)
        out_ft[:, :, :self.modes1, :self.modes2] = self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)
        out_ft[:, :, -self.modes1:, :self.modes2] = self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)

        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))
        return x

class FNO2dWithoutInvariantLayer(nn.Module):
    def __init__(self, fno_architecture, device=None, padding_frac=1 / 8):
        super(FNO2dWithoutInvariantLayer, self).__init__()
        self.modes1 = fno_architecture["modes"]
        self.modes2 = fno_architecture["modes"]
        self.width = fno_architecture["width"]
        self.n_layers = fno_architecture["n_layers"]
        self.retrain_fno = fno_architecture["retrain_fno"]

        torch.manual_seed(self.retrain_fno)
        self.padding_frac = padding_frac
        self.fc0 = nn.Conv2d(1, self.width, kernel_size=1)

        self.conv_list = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(self.n_layers)])
        self.spectral_list = nn.ModuleList([SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(self.n_layers)])

        self.fc1 = nn.Conv2d(self.width, 128, kernel_size=1)
        self.fc2 = nn.Conv2d(128, 1, kernel_size=1)

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

        self.to(device)

    def forward(self, x):
        x = self.fc0(x)

        x1_padding = int(round(x.shape[-1] * self.padding_frac))
        x2_padding = int(round(x.shape[-2] * self.padding_frac))
        x = F.pad(x, [x1_padding, x1_padding, x2_padding, x2_padding])

        for k, (s, c) in enumerate(zip(self.spectral_list, self.conv_list)):
            x1 = s(x)
            x2 = c(x)
            x = x1 + x2
            if k != self.n_layers - 1:
                x = F.gelu(x)

        x = x[..., x2_padding:-x2_padding, x1_padding:-x1_padding]

        x = self.fc1(x)
        x = F.gelu(x)
        x = self.fc2(x)

        classification_output = self.classifier(x)
        return x, classification_output

class FNO2dWithInvariantLayer(nn.Module):
    def __init__(self, fno_architecture, device=None, padding_frac=1 / 8):
        super(FNO2dWithInvariantLayer, self).__init__()
        self.modes1 = fno_architecture["modes"]
        self.modes2 = fno_architecture["modes"]
        self.width = fno_architecture["width"]
        self.n_layers = fno_architecture["n_layers"]
        self.retrain_fno = fno_architecture["retrain_fno"]

        torch.manual_seed(self.retrain_fno)
        self.padding_frac = padding_frac
        self.fc0 = nn.Conv2d(1, self.width, kernel_size=1)

        self.conv_list = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(self.n_layers)])
        self.spectral_list = nn.ModuleList([SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(self.n_layers)])
        self.discretization_invariant_list = nn.ModuleList([ExtendedDiscretizationInvariantLayer(self.width) for _ in range(self.n_layers)])

        self.fc1 = nn.Conv2d(self.width, 128, kernel_size=1)
        self.fc2 = nn.Conv2d(128, 1, kernel_size=1)

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

        self.to(device)

    def forward(self, x):
        x = self.fc0(x)

        x1_padding = int(round(x.shape[-1] * self.padding_frac))
        x2_padding = int(round(x.shape[-2] * self.padding_frac))
        x = F.pad(x, [x1_padding, x1_padding, x2_padding, x2_padding])

        for k, (s, c, d) in enumerate(zip(self.spectral_list, self.conv_list, self.discretization_invariant_list)):
            x1 = s(x)
            x2 = c(x)
            x3 = d(x)
            x = x1 + x2 + x3
            if k != self.n_layers - 1:
                x = F.gelu(x)

        x = x[..., x2_padding:-x2_padding, x1_padding:-x1_padding]

        x = self.fc1(x)
        x = F.gelu(x)
        x = self.fc2(x)

        classification_output = self.classifier(x)
        return x, classification_output

class BasicBlock(nn.Module):
    def __init__(self, in_planes, out_planes, kernel_size=1, stride=1):
        super(BasicBlock, self).__init__()
        if isinstance(kernel_size, tuple):
            padding = (kernel_size[0] // 2, kernel_size[1] // 2)
        else:
            padding = kernel_size // 2
        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride=stride, padding=padding, padding_mode='circular', bias=False)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.relu(x)
        return x

# CNN without Discretization Invariant Layer
class SimpleCNN(nn.Module):
    def __init__(self, mean=0.0, std=1.0, act_fun=nn.ReLU(),
                 mid_channels=32, out_channels=64, kernel1=5, kernel2=5, stride=1):
        super(SimpleCNN, self).__init__()
        self.mean = mean
        self.std = std
        self.act_fun = act_fun
        self.kernel1 = kernel1
        self.kernel2 = kernel2
        self.stride = stride
        self.layer1 = BasicBlock(1, mid_channels, kernel_size=(kernel1, kernel2), stride=self.stride)
        self.layer2 = BasicBlock(mid_channels, out_channels, kernel_size=(kernel1, kernel2), stride=self.stride)
        self.conv3 = nn.Conv2d(out_channels, 1, kernel_size=1)

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = (x - self.mean) / self.std
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.conv3(x)

        classification_output = self.classifier(x)
        return x, classification_output

    def name(self):
        return f'simple-cnn-{self.kernel1}-{self.kernel2}'

# CNN with Discretization Invariant Layer
class CNNWithInvariantLayer(nn.Module):
    def __init__(self, mean=0.0, std=1.0, act_fun=nn.ReLU(),
                 mid_channels=32, out_channels=64, kernel1=5, kernel2=5, stride=1):
        super(CNNWithInvariantLayer, self).__init__()
        self.mean = mean
        self.std = std
        self.act_fun = act_fun
        self.kernel1 = kernel1
        self.kernel2 = kernel2
        self.stride = stride
        self.layer1 = BasicBlock(1, mid_channels, kernel_size=(kernel1, kernel2), stride=self.stride)
        self.layer2 = BasicBlock(mid_channels, out_channels, kernel_size=(kernel1, kernel2), stride=self.stride)
        self.inv_layer = ExtendedDiscretizationInvariantLayer(out_channels)
        self.conv3 = nn.Conv2d(out_channels, 1, kernel_size=1)

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = (x - self.mean) / self.std
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.inv_layer(x)
        x = self.conv3(x)

        classification_output = self.classifier(x)
        return x, classification_output

    def name(self):
        return f'cnn-invariant-{self.kernel1}-{self.kernel2}'

# Sobolev norm using Fourier transformation on a torus
def sobolev_norm_fourier_2d(image, k=2):
    """
    Compute the Sobolev norm using 2D Fourier transformation on a torus.
    :param image: 2D input tensor, assuming shape (batch, channels, height, width).
    :param k: Order of the Sobolev norm.
    :return: Sobolev norm values for each element in the batch.
    """
    image_fft = torch.fft.fft2(image)

    batch_size, channels, height, width = image.shape
    freqs_x = torch.fft.fftfreq(width)
    freqs_y = torch.fft.fftfreq(height)
    freqs_x, freqs_y = torch.meshgrid(freqs_x, freqs_y, indexing='ij')

    freqs_squared = (freqs_x.unsqueeze(0).unsqueeze(0).to(image.device) ** 2 +
                     freqs_y.unsqueeze(0).unsqueeze(0).to(image.device) ** 2)

    sobolev_weights = (1 + freqs_squared) ** (k / 2)

    sobolev_norms = (sobolev_weights.unsqueeze(2) * torch.abs(image_fft) ** 2).sum((-2, -1)).sqrt()

    return sobolev_norms.mean(dim=(1, 2))  # Average over channels for each batch element

def linf_norm(pred, target):
    """Compute the L-infinity norm, which is the maximum absolute difference."""
    return torch.max(torch.abs(pred - target)).item()

def l2_error(pred, target):
    """Compute the L2 error."""
    return F.mse_loss(pred, target).item()

# Parameters for FNO2d
fno_architecture = {
    "modes": 16,
    "width": 32,
    "n_layers": 4,
    "retrain_fno": 42
}

# Initialize models
model_fno_with_invariant = FNO2dWithInvariantLayer(fno_architecture, device=device).to(device)
model_fno_without_invariant = FNO2dWithoutInvariantLayer(fno_architecture, device=device).to(device)
model_cnn_with_invariant = CNNWithInvariantLayer().to(device)
model_cnn_without_invariant = SimpleCNN().to(device)

optimizers = {
    'FNO with Invariant': optim.Adam(model_fno_with_invariant.parameters(), lr=0.001),
    'FNO without Invariant': optim.Adam(model_fno_without_invariant.parameters(), lr=0.001),
    'CNN with Invariant': optim.Adam(model_cnn_with_invariant.parameters(), lr=0.001),
    'CNN without Invariant': optim.Adam(model_cnn_without_invariant.parameters(), lr=0.001)
}

# Training loop
num_epochs = 3
for epoch in range(num_epochs):
    model_fno_with_invariant.train()
    model_fno_without_invariant.train()
    model_cnn_with_invariant.train()
    model_cnn_without_invariant.train()

    for blurred, original, labels in train_loader:
        blurred, original, labels = blurred.to(device), original.to(device), labels.to(device)

        # Train all models
        for name, (model, optimizer) in zip(
            optimizers.keys(),
            [
                (model_fno_with_invariant, optimizers['FNO with Invariant']),
                (model_fno_without_invariant, optimizers['FNO without Invariant']),
                (model_cnn_with_invariant, optimizers['CNN with Invariant']),
                (model_cnn_without_invariant, optimizers['CNN without Invariant']),
            ]
        ):
            optimizer.zero_grad()
            outputs, class_outputs = model(blurred)
            loss = F.mse_loss(outputs, original)
            class_loss = F.cross_entropy(class_outputs, labels)
            total_loss = loss + class_loss
            total_loss.backward()
            optimizer.step()

# Evaluation function
def evaluate_and_display_results(models, val_loader, device):
    results = {"Model": [], "Sobolev Norm": [], "L-infinity Norm": [], "L2 Error": []}

    for model_name, model in models.items():
        model.eval()
        sobolev_norms, linf_norms, l2_errors = [], [], []

        with torch.no_grad():
            for blurred, original, _ in val_loader:
                blurred, original = blurred.to(device), original.to(device)

                # Evaluate model
                outputs, _ = model(blurred)
                sobolev = sobolev_norm_fourier_2d(outputs, k=2).mean().item()
                linf = linf_norm(outputs, original)
                l2 = l2_error(outputs, original)

                sobolev_norms.append(sobolev)
                linf_norms.append(linf)
                l2_errors.append(l2)

        # Store results
        results["Model"].append(model_name)
        results["Sobolev Norm"].append(sum(sobolev_norms)/len(sobolev_norms))
        results["L-infinity Norm"].append(sum(linf_norms)/len(linf_norms))
        results["L2 Error"].append(sum(l2_errors)/len(l2_errors))

    # Display Results
    for model_name in results['Model']:
        print(f"Results for {model_name}:")
        idx = results['Model'].index(model_name)
        print(f"  Sobolev Norm Mean: {results['Sobolev Norm'][idx]:.4f}")
        print(f"  L-infinity Norm Mean: {results['L-infinity Norm'][idx]:.4f}")
        print(f"  L2 Error Mean: {results['L2 Error'][idx]:.4f}")
        print("")

# Conduct the evaluation for all models and display results
models_to_evaluate = {
    "FNO with Invariant": model_fno_with_invariant,
    "FNO without Invariant": model_fno_without_invariant,
    "CNN with Invariant": model_cnn_with_invariant,
    "CNN without Invariant": model_cnn_without_invariant,
}

evaluate_and_display_results(models_to_evaluate, val_loader, device)
