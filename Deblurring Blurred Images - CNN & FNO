import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
from torch.fft import rfft2, irfft2
import torch.nn.functional as F

# Set device for computation
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Load MNIST dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# Use the full training and test datasets
train_dataset = datasets.MNIST(root='mnist_data', train=True, transform=transform, download=True)
val_dataset = datasets.MNIST(root='mnist_data', train=False, transform=transform, download=True)

# Create DataLoader for training and validation datasets
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# Function to apply Gaussian blur to images
def apply_gaussian_blur(images, blur_transform):
    blurred_images = torch.stack([blur_transform(image) for image in images])
    return blurred_images.to(device)

# Define the Gaussian blur transformation
gaussian_blur = transforms.GaussianBlur(kernel_size=5, sigma=1.0)

# Preprocess the entire dataset with Gaussian blur
def preprocess_data(loader, blur_transform):
    blurred_images, original_images, labels = [], [], []
    for images, lbls in loader:
        images = images.to(device)
        blurred_images.append(apply_gaussian_blur(images, blur_transform))
        original_images.append(images)
        labels.append(lbls)
    blurred_images = torch.cat(blurred_images)
    original_images = torch.cat(original_images)
    labels = torch.cat(labels)
    return blurred_images, original_images, labels

train_blurred_images, train_original_images, train_labels = preprocess_data(train_loader, gaussian_blur)
val_blurred_images, val_original_images, val_labels = preprocess_data(val_loader, gaussian_blur)

# Create DataLoader for blurred data
class BlurDataset(torch.utils.data.Dataset):
    def __init__(self, blurred_images, original_images, labels):
        assert len(blurred_images) == len(original_images) == len(labels)
        self.blurred_images = blurred_images
        self.original_images = original_images
        self.labels = labels

    def __len__(self):
        return len(self.blurred_images)

    def __getitem__(self, idx):
        return self.blurred_images[idx], self.original_images[idx], self.labels[idx]

train_dataset = BlurDataset(train_blurred_images, train_original_images, train_labels)
val_dataset = BlurDataset(val_blurred_images, val_original_images, val_labels)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

# 2D Fourier layer
class SpectralConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, modes1, modes2):
        super(SpectralConv2d, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.modes1 = modes1
        self.modes2 = modes2

        self.scale = 1 / (in_channels * out_channels)
        self.weights1 = nn.Parameter(
            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))
        self.weights2 = nn.Parameter(
            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))

    def compl_mul2d(self, input, weights):
        return torch.einsum("bixy,ioxy->boxy", input, weights)

    def forward(self, x):
        batchsize = x.shape[0]
        x_ft = rfft2(x, dim=(-2, -1))

        out_ft = torch.zeros(
            batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat, device=x.device)
        out_ft[:, :, :self.modes1, :self.modes2] = self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)
        out_ft[:, :, -self.modes1:, :self.modes2] = self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)

        x = irfft2(out_ft, s=(x.size(-2), x.size(-1)))
        return x

# Custom Discretization Invariant Layer
class DiscretizationInvariantLayer(nn.Module):
    def __init__(self, channels):
        super(DiscretizationInvariantLayer, self).__init__()
        self.channels = channels
        self.adaptive_pool = nn.AdaptiveAvgPool2d(1)

    def forward(self, x):
        x_pooled = self.adaptive_pool(x)
        return x - x_pooled

# Fourier Neural Operator with Discretization Invariant Layers
class FNO2d(nn.Module):
    def __init__(self, fno_architecture, device=None, padding_frac=1 / 8):
        super(FNO2d, self).__init__()
        self.modes1 = fno_architecture["modes"]
        self.modes2 = fno_architecture["modes"]
        self.width = fno_architecture["width"]
        self.n_layers = fno_architecture["n_layers"]
        self.retrain_fno = fno_architecture["retrain_fno"]

        torch.manual_seed(self.retrain_fno)
        self.padding_frac = padding_frac
        self.fc0 = nn.Conv2d(1, self.width, kernel_size=1)
        self.conv_list = nn.ModuleList([nn.Conv2d(self.width, self.width, 1) for _ in range(self.n_layers)])
        self.spectral_list = nn.ModuleList([SpectralConv2d(self.width, self.width, self.modes1, self.modes2) for _ in range(self.n_layers)])
        self.discretization_invariant_list = nn.ModuleList([DiscretizationInvariantLayer(self.width) for _ in range(self.n_layers)])
        self.fc1 = nn.Conv2d(self.width, 128, kernel_size=1)
        self.fc2 = nn.Conv2d(128, 1, kernel_size=1)

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

        self.to(device)

    def forward(self, x):
        x = self.fc0(x)

        x1_padding = int(round(x.shape[-1] * self.padding_frac))
        x2_padding = int(round(x.shape[-2] * self.padding_frac))
        x = F.pad(x, [x1_padding, x1_padding, x2_padding, x2_padding])

        for k, (s, c, d) in enumerate(zip(self.spectral_list, self.conv_list, self.discretization_invariant_list)):
            x1 = s(x)
            x2 = c(x)
            x3 = d(x)
            x = x1 + x2 + x3
            if k != self.n_layers - 1:
                x = F.gelu(x)

        x = x[..., x2_padding:-x2_padding, x1_padding:-x1_padding]

        x = self.fc1(x)
        x = F.gelu(x)
        x = self.fc2(x)

        classification_output = self.classifier(x)
        return x, classification_output

# Initialize the CNN
class BasicBlock(nn.Module):
    def __init__(self, in_planes, out_planes, kernel_size=1, stride=1):
        super(BasicBlock, self).__init__()
        if isinstance(kernel_size, tuple):
            padding = (kernel_size[0] // 2, kernel_size[1] // 2)
        else:
            padding = kernel_size // 2
        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size, stride=stride, padding=padding, padding_mode='circular', bias=False)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.conv(x)
        x = self.relu(x)
        return x

class CNN(nn.Module):
    def __init__(self, mean=0.0, std=1.0, act_fun=nn.ReLU(),
                 mid_channels=32, out_channels=64, kernel1=5, kernel2=5, stride=1):
        super(CNN, self).__init__()
        self.mean = mean
        self.std = std
        self.act_fun = act_fun
        self.kernel1 = kernel1
        self.kernel2 = kernel2
        self.stride = stride
        self.layer1 = BasicBlock(1, mid_channels, kernel_size=(kernel1, kernel2), stride=self.stride)
        self.layer2 = BasicBlock(mid_channels, out_channels, kernel_size=(kernel1, kernel2), stride=self.stride)
        self.conv3 = nn.Conv2d(out_channels, 1, kernel_size=1)

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28 * 28, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = (x - self.mean) / self.std
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.conv3(x)

        classification_output = self.classifier(x)
        return x, classification_output

    def name(self):
        return f'cnn-{self.kernel1}-{self.kernel2}'

# Define Sobolev Norm (L2)
def sobolev_loss(pred, target, order=1, weight=1.0):
    """Compute the Sobolev loss focusing on the first and higher-order derivative losses."""
    loss = F.mse_loss(pred, target)

    for i in range(1, order + 1):
        # X derivative up to the specified order
        diff_pred_x = torch.diff(pred, n=i, dim=-1)
        diff_target_x = torch.diff(target, n=i, dim=-1)

        # Y derivative up to the specified order
        diff_pred_y = torch.diff(pred, n=i, dim=-2)
        diff_target_y = torch.diff(target, n=i, dim=-2)

        # Add these differences squared into loss, scaling for regularity
        loss += weight * (F.mse_loss(diff_pred_x, diff_target_x) + F.mse_loss(diff_pred_y, diff_target_y))

    return loss

# Define Frechet differential norm (alternative definition considering more general derivative)
def frechet_loss(pred, target, weight=1.0):
    """Compute a modified Frechet loss by considering non-linear operations and complex mappings."""
    loss = F.mse_loss(pred, target)

    for i in range(2):
        # Non-linear combination extensions example: quadratic or interaction terms
        pred_squared = torch.square(pred)
        target_squared = torch.square(target)

        # Considering interactions in spatial domains
        interaction_pred_x = torch.einsum('...ij,...kj->...ik', pred, pred)
        interaction_target_x = torch.einsum('...ij,...kj->...ik', target, target)

        interaction_pred_y = torch.einsum('...ji,...jk->...ik', pred, pred)
        interaction_target_y = torch.einsum('...ji,...jk->...ik', target, target)

        # Add these interactions and align them within the loss computation
        loss += weight * (F.mse_loss(interaction_pred_x, interaction_target_x) +
                          F.mse_loss(interaction_pred_y, interaction_target_y))

    return loss

# Compute L-infinity Norm
def linf_norm(pred, target):
    """Compute the L-infinity norm, which is the maximum absolute difference."""
    return torch.max(torch.abs(pred - target)).item()

# New functions to calculate Sobolev norms and embedding estimates
def sobolev_norm(u, k, p):
    """Compute the Sobolev norm and return an estimate of max|u(x)|."""
    norm = torch.tensor(0.0, device=u.device)
    norm += torch.sum(torch.abs(u)**p)**(1 / p)

    for order in range(1, k + 1):
        if order == 1:
            du_h = F.pad(u[:, :, 1:] - u[:, :, :-1], (0, 1, 0, 0))
            du_v = F.pad(u[:, :, :, 1:] - u[:, :, :, :-1], (0, 0, 0, 1))
            norm += torch.sum(torch.abs(du_h)**p)**(1/p) + torch.sum(torch.abs(du_v)**p)**(1/p)
        else:
            du_hh = F.pad(du_h[:, :, 1:] - du_h[:, :, :-1], (0, 1, 0, 0))
            du_vv = F.pad(du_v[:, :, :, 1:] - du_v[:, :, :, :-1], (0, 0, 0, 1))
            norm += torch.sum(torch.abs(du_hh)**p)**(1/p) + torch.sum(torch.abs(du_vv)**p)**(1/p)

    # Estimate max|u(x)| using Sobolev embedding theorem in 2D
    C = 1.0  # constant from the embedding theorem, adjust as necessary
    max_abs_estimate = C * norm

    return norm, max_abs_estimate

def sobolev_norm_embedded(u, k, p):
    """Compute the Sobolev norm and related estimates."""
    norm = torch.tensor(0.0, device=u.device)
    norm += torch.sum(torch.abs(u)**p)**(1 / p)

    for order in range(1, k + 1):
        if order == 1:
            du_h = F.pad(u[:, :, 1:] - u[:, :, :-1], (0, 1, 0, 0))
            du_v = F.pad(u[:, :, :, 1:] - u[:, :, :, :-1], (0, 0, 0, 1))
            norm += torch.sum(torch.abs(du_h)**p)**(1/p) + torch.sum(torch.abs(du_v)**p)**(1/p)
        else:
            du_hh = F.pad(du_h[:, :, 1:] - du_h[:, :, :-1], (0, 1, 0, 0))
            du_vv = F.pad(du_v[:, :, :, 1:] - du_v[:, :, :, :-1], (0, 0, 0, 1))
            norm += torch.sum(torch.abs(du_hh)**p)**(1/p) + torch.sum(torch.abs(du_vv)**p)**(1/p)

    max_abs_estimate = None
    c0_semi_norm_estimate = None

    if k >= 1:
        C_max_abs = 1.0  # Calibration needed for practical use
        max_abs_estimate = C_max_abs * norm

        if k == 1:
            n = 2  # Image with 2D domain
            C_c0 = 1.0  # Calibration needed for C0,1âˆ’n/p type norm
            semi_norm_factor = 1 - n / p
            c0_semi_norm_estimate = C_c0 * norm ** semi_norm_factor

    return norm, max_abs_estimate, c0_semi_norm_estimate

# Parameters for FNO2d
fno_architecture = {
    "modes": 16,
    "width": 32,
    "n_layers": 4,
    "retrain_fno": 42
}

# Initialize the models
model_fno = FNO2d(fno_architecture, device=device).to(device)
model_cnn = CNN().to(device)

criterion = nn.MSELoss()
classification_criterion = nn.CrossEntropyLoss()
optimizer_fno = optim.Adam(model_fno.parameters(), lr=0.001)
optimizer_cnn = optim.Adam(model_cnn.parameters(), lr=0.001)

# Initialize error lists
sobolev_val_l2_errors_fno = []
frechet_val_l2_errors_fno = []
sobolev_val_l2_errors_cnn = []
frechet_val_l2_errors_cnn = []

sobolev_val_linf_errors_fno = []
frechet_val_linf_errors_fno = []
sobolev_val_linf_errors_cnn = []
frechet_val_linf_errors_cnn = []

# Training loop
num_epochs = 20
for epoch in range(num_epochs):
    model_fno.train()
    model_cnn.train()
    running_loss_sobolev_fno, running_loss_frechet_fno = 0.0, 0.0
    running_linf_sobolev_fno, running_linf_frechet_fno = 0.0, 0.0
    running_loss_sobolev_cnn, running_loss_frechet_cnn = 0.0, 0.0
    running_linf_sobolev_cnn, running_linf_frechet_cnn = 0.0, 0.0

    for blurred, original, labels in train_loader:
        blurred, original, labels = blurred.to(device), original.to(device), labels.to(device)

        # Training FNO model with Sobolev
        optimizer_fno.zero_grad()
        outputs_fno, class_outputs_fno = model_fno(blurred)
        loss_sobolev_fno = sobolev_loss(outputs_fno, original, order=2, weight=0.1)
        class_loss_fno = classification_criterion(class_outputs_fno, labels)
        total_loss_sobolev_fno = loss_sobolev_fno + class_loss_fno
        total_loss_sobolev_fno.backward(retain_graph=True)
        optimizer_fno.step()
        running_loss_sobolev_fno += loss_sobolev_fno.item()
        running_linf_sobolev_fno += linf_norm(outputs_fno, original)

        # Training FNO model with Frechet
        optimizer_fno.zero_grad()
        outputs_fno, class_outputs_fno = model_fno(blurred)  # Recompute because we stepped optimizer before
        loss_frechet_fno = frechet_loss(outputs_fno, original, weight=0.1)
        class_loss_fno = classification_criterion(class_outputs_fno, labels)  # Need recompute since optimizer step
        total_loss_frechet_fno = loss_frechet_fno + class_loss_fno
        total_loss_frechet_fno.backward()
        optimizer_fno.step()
        running_loss_frechet_fno += loss_frechet_fno.item()
        running_linf_frechet_fno += linf_norm(outputs_fno, original)

        # Training CNN model with Sobolev
        optimizer_cnn.zero_grad()
        outputs_cnn, class_outputs_cnn = model_cnn(blurred)
        loss_sobolev_cnn = sobolev_loss(outputs_cnn, original, order=2, weight=0.1)
        class_loss_cnn = classification_criterion(class_outputs_cnn, labels)
        total_loss_sobolev_cnn = loss_sobolev_cnn + class_loss_cnn
        total_loss_sobolev_cnn.backward(retain_graph=True)
        optimizer_cnn.step()
        running_loss_sobolev_cnn += loss_sobolev_cnn.item()
        running_linf_sobolev_cnn += linf_norm(outputs_cnn, original)

        # Training CNN model with Frechet
        optimizer_cnn.zero_grad()
        outputs_cnn, class_outputs_cnn = model_cnn(blurred)  # Recompute because we stepped optimizer before
        loss_frechet_cnn = frechet_loss(outputs_cnn, original, weight=0.1)
        class_loss_cnn = classification_criterion(class_outputs_cnn, labels)  # Need recompute since optimizer step
        total_loss_frechet_cnn = loss_frechet_cnn + class_loss_cnn
        total_loss_frechet_cnn.backward()
        optimizer_cnn.step()
        running_loss_frechet_cnn += loss_frechet_cnn.item()
        running_linf_frechet_cnn += linf_norm(outputs_cnn, original)

    # Validation
    model_fno.eval()
    model_cnn.eval()
    with torch.no_grad():
        for blurred, original, labels in val_loader:
            blurred, original, labels = blurred.to(device), original.to(device), labels.to(device)

            # Validation for FNO model
            outputs_fno, class_outputs_fno = model_fno(blurred)
            sobolev_norm_fno, max_abs_estimate_fno = sobolev_norm(outputs_fno, k=2, p=2)
            embedded_norm_fno, embedded_max_abs_fno, embedded_semi_norm_fno = sobolev_norm_embedded(outputs_fno, k=2, p=2)

            # Handle potential None values
            max_abs_estimate_fno = max_abs_estimate_fno if max_abs_estimate_fno is not None else 0.0
            embedded_semi_norm_fno = embedded_semi_norm_fno if embedded_semi_norm_fno is not None else 0.0

            # Print Sobolev norm estimates
            print(f'FNO Sobolev Norm: {sobolev_norm_fno.item()}, Max|u(x)|: {max_abs_estimate_fno}, '
                  f'Embedded Norm: {embedded_norm_fno.item()}, Max|u(x)|: {embedded_max_abs_fno}, '
                  f'Semi-norm: {embedded_semi_norm_fno}')

            # Validation for CNN model
            outputs_cnn, class_outputs_cnn = model_cnn(blurred)
            sobolev_norm_cnn, max_abs_estimate_cnn = sobolev_norm(outputs_cnn, k=2, p=2)
            embedded_norm_cnn, embedded_max_abs_cnn, embedded_semi_norm_cnn = sobolev_norm_embedded(outputs_cnn, k=2, p=2)

            # Handle potential None values
            max_abs_estimate_cnn = max_abs_estimate_cnn if max_abs_estimate_cnn is not None else 0.0
            embedded_semi_norm_cnn = embedded_semi_norm_cnn if embedded_semi_norm_cnn is not None else 0.0

            # Print Sobolev norm estimates
            print(f'CNN Sobolev Norm: {sobolev_norm_cnn.item()}, Max|u(x)|: {max_abs_estimate_cnn}, '
                  f'Embedded Norm: {embedded_norm_cnn.item()}, Max|u(x)|: {embedded_max_abs_cnn}, '
                  f'Semi-norm: {embedded_semi_norm_cnn}')

    # Example of calculating average values for presentation (replace with your actual computations)
    avg_val_sobolev_norm_fno = running_loss_sobolev_fno / len(train_loader)  # Produce an average loss over the validation set
    avg_val_frechet_norm_fno = running_loss_frechet_fno / len(train_loader)

    avg_val_sobolev_norm_cnn = running_loss_sobolev_cnn / len(train_loader)  # Produce an average loss over the validation set
    avg_val_frechet_norm_cnn = running_loss_frechet_cnn / len(train_loader)

    avg_linf_sobolev_fno = running_linf_sobolev_fno / len(train_loader)
    avg_linf_frechet_fno = running_linf_frechet_fno / len(train_loader)
    avg_linf_sobolev_cnn = running_linf_sobolev_cnn / len(train_loader)
    avg_linf_frechet_cnn = running_linf_frechet_cnn / len(train_loader)

    sobolev_val_l2_errors_fno.append(avg_val_sobolev_norm_fno)
    frechet_val_l2_errors_fno.append(avg_val_frechet_norm_fno)

    sobolev_val_l2_errors_cnn.append(avg_val_sobolev_norm_cnn)
    frechet_val_l2_errors_cnn.append(avg_val_frechet_norm_cnn)

    sobolev_val_linf_errors_fno.append(avg_linf_sobolev_fno)
    frechet_val_linf_errors_fno.append(avg_linf_frechet_fno)

    sobolev_val_linf_errors_cnn.append(avg_linf_sobolev_cnn)
    frechet_val_linf_errors_cnn.append(avg_linf_frechet_cnn)

# Plotting the errors
epochs = list(range(1, num_epochs + 1))

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(epochs, sobolev_val_l2_errors_fno, label='FNO Sobolev L2 Error')
plt.plot(epochs, frechet_val_l2_errors_fno, label='FNO Frechet L2 Error')
plt.plot(epochs, sobolev_val_l2_errors_cnn, label='CNN Sobolev L2 Error')
plt.plot(epochs, frechet_val_l2_errors_cnn, label='CNN Frechet L2 Error')
plt.xlabel('Epoch')
plt.ylabel('L2 Error')
plt.title('L2 Error across Epochs')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, sobolev_val_linf_errors_fno, label='FNO Sobolev L_inf Error')
plt.plot(epochs, frechet_val_linf_errors_fno, label='FNO Frechet L_inf Error')
plt.plot(epochs, sobolev_val_linf_errors_cnn, label='CNN Sobolev L_inf Error')
plt.plot(epochs, frechet_val_linf_errors_cnn, label='CNN Frechet L_inf Error')
plt.xlabel('Epoch')
plt.ylabel('L_inf Error')
plt.title('L_inf Error across Epochs')
plt.legend()

plt.tight_layout()
plt.show()

# Visualization function
def visualize_images(original_images, blurred_images, deblurred_images_fno, deblurred_images_cnn, num_images=5):
    fig, axs = plt.subplots(4, num_images, figsize=(15, 10))
    for i in range(num_images):
        axs[0, i].imshow(original_images[i].squeeze().cpu(), cmap='gray')
        axs[0, i].set_title('Original')
        axs[0, i].axis('off')

        axs[1, i].imshow(blurred_images[i].squeeze().cpu(), cmap='gray')
        axs[1, i].set_title('Blurred')
        axs[1, i].axis('off')

        axs[2, i].imshow(deblurred_images_fno[i].squeeze().cpu(), cmap='gray')
        axs[2, i].set_title('Deblurred (FNO)')
        axs[2, i].axis('off')

        axs[3, i].imshow(deblurred_images_cnn[i].squeeze().cpu(), cmap='gray')
        axs[3, i].set_title('Deblurred (CNN)')
        axs[3, i].axis('off')

    plt.show()

# Visualization of differences
def visualize_differences(original_images, deblurred_images_fno, deblurred_images_cnn, num_images=5):
    fig, axs = plt.subplots(3, num_images, figsize=(15, 8))
    for i in range(num_images):
        original = original_images[i].squeeze().cpu().numpy()
        deblurred_fno = deblurred_images_fno[i].squeeze().cpu().numpy()
        deblurred_cnn = deblurred_images_cnn[i].squeeze().cpu().numpy()

        # Calculate differences
        difference_fno = abs(original - deblurred_fno)
        difference_cnn = abs(original - deblurred_cnn)

        # Display differences
        axs[0, i].imshow(original, cmap='gray')
        axs[0, i].set_title('Original')
        axs[0, i].axis('off')

        axs[1, i].imshow(difference_fno, cmap='hot')
        axs[1, i].set_title('Difference FNO')
        axs[1, i].axis('off')

        axs[2, i].imshow(difference_cnn, cmap='hot')
        axs[2, i].set_title('Difference CNN')
        axs[2, i].axis('off')

    plt.tight_layout()
    plt.show()

# Example of visualizing differences
with torch.no_grad():
    model_fno.eval()
    model_cnn.eval()
    blurred_sample, original_sample, label_sample = next(iter(val_loader))
    blurred_sample, original_sample = blurred_sample.to(device), original_sample.to(device)
    deblurred_sample_fno, _ = model_fno(blurred_sample)
    deblurred_sample_cnn, _ = model_cnn(blurred_sample)

    visualize_images(original_sample, blurred_sample, deblurred_sample_fno, deblurred_sample_cnn)
    visualize_differences(original_sample, deblurred_sample_fno, deblurred_sample_cnn)
